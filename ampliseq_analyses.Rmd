---
title: "Social network position is a major predictor of ant behaviour, microbiota composition, and brain gene expression: gut microbiota analyses - R Notebook - Joanito Liberti"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

# Place the raw data into a folder named RawFiles. Change PATH throughout the code to match your own path
# Number of reads per sample
```{bash}
cd PATH/RawFiles/
for f in *fastq.gz; do
echo $f
echo $(zless $f | wc -l)/4|bc
done
```


# First check the quality of your data with FastQC
```{bash, eval=FALSE}
mkdir PATH/DADA2/
mkdir PATH/DADA2/analysis
mkdir PATH/DADA2/analysis/00_FASTQC/
  cd PATH/RawFiles
for f in *.fastq.gz; do 
fastqc $f -o PATH/DADA2/analysis/00_FASTQC/; 
done
```

# Clean up sample names
```{bash}
cd PATH/RawFiles
for f in *fastq.gz; do mv $f ${f/_001_*/.fastq.gz}; done
for f in *fastq.gz; do mv $f ${f//_/.}; done
for f in *fastq.gz; do mv $f ${f/CFG./}; done
```

# Remove primers and anything before and after with Cutadapt
```{bash, eval=FALSE}
mkdir PATH/DADA2/analysis/02_dada2
cd PATH/RawFiles
  for f in *R1.fastq.gz; do 
/Users/joanitoliberti/Library/Python/2.7/bin//cutadapt -G GGACTACHVGGGTWTCTAAT -g GTGCCAGCMGCCGCGGTAA -o ${f/.fastq/.cut.fastq} -p ${f/R1.fastq/R2.cut.fastq} $f ${f/R1.fastq/R2.fastq} --pair-filter=any; done
```

# Move trimmed reads into a separate folder
```{bash}
mkdir PATH/DADA2/analysis/01_trimmed
cd PATH/RawFiles
for f in *cut.fastq.gz; do mv $f PATH/DADA2/analysis/01_trimmed/$f; done
```

# Edit sample names
```{bash}
cd PATH/DADA2/analysis/01_trimmed
for f in *cut.fastq.gz; do mv $f ${f/L1./}; done
```

# Number of reads per sample after cutadapt
```{bash}
cd PATH/RawFiles/

echo -e "Sample""\t""Raw""\t""Cutadapt"

for f in $(ls *R1.fastq.gz | cut -d '.' -f 1|sort|uniq); do
raw=`echo $(zless PATH/RawFiles/$f.L1.R1.fastq.gz | wc -l)/4|bc`
cut=`echo $(zless PATH/DADA2/analysis/01_trimmed/$f.L1.R1.cut.fastq.gz | wc -l)/4|bc`

echo -e $f"\t"$raw"\t"$cut
done
```

# Now we can feed the quality-filtered reads to the DADA2 pipeline
## First, install required packages if needed (uncomment all installation lines)
```{r, eval=FALSE}
# if (!requireNamespace("BiocManager", quietly = TRUE))
#   install.packages("BiocManager")
# BiocManager::install(version = "3.10")
# BiocManager::install("dada2", version = "3.10")
# BiocManager::install("DECIPHER")
# BiocManager::install("phyloseq")
# BiocManager::install("biomformat")
# BiocManager::install("ShortRead")
# BiocManager::install("Biostrings")
# BiocManager::install("genefilter")
# BiocManager::install("decontam")
# BiocManager::install("DESeq2")

# install.packages("ggplot2")
# install.packages("phangorn")
# install.packages("vegan")
# install.packages("dplyr")
# install.packages("scales")
# install.packages("RColorBrewer")
# install.packages(“reshape2”)
# install.packages("cowplot")
# install.packages("tidyverse")
# install.packages("readxl")
# install.packages("ggbeeswarm")
# install.packages("magrittr")
# install.packages("ggpubr")
# install.packages('dendextend')
# install.packages("multcomp")
# install.packages("GUniFrac")

# Load libraries
library(dada2)
library(ShortRead)
library(Biostrings)
library(ggplot2)
library(biomformat)
```

# **Set the working directory (in R notebook the working directory needs to be assigned within a "setup" chunk, or it will only work within the individual chunks in which it was set)**
```{r setup}
path <- "PATH/DADA2/analysis/02_dada2"
knitr::opts_knit$set(root.dir = normalizePath(path)) 
```

```{r, eval=FALSE}
library(dada2); packageVersion("dada2")
pathraw <-"PATH/DADA2/analysis/01_trimmed"

list.files(pathraw)
# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.trim.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(pathraw, pattern="R1.cut.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(pathraw, pattern="R2.cut.fastq.gz", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "\\."), `[`, 1)
sample.names
```

# Quality scores
```{r}
path<-"PATH/DADA2/analysis/01_trimmed"
dev.new()
# Quality scores of R1 reads
plotQualityProfile(fnFs[1:20]) 
plotQualityProfile(fnFs[21:40])
plotQualityProfile(fnFs[41:60])

# Quality scores of R2 reads
plotQualityProfile(fnRs[1:20]) 
plotQualityProfile(fnRs[21:40])
plotQualityProfile(fnRs[41:60])
```

# Trim the data
```{r}
# Place filtered files in filtered/ subdirectory
path<-"PATH/DADA2/analysis/02_dada2"
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names

sys_str <- Sys.time()
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(232,231), # truncLen[[1]] + truncLen[[2]] > amplicon_length+25
                     maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,      
                     compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
sys_str[2] <- Sys.time()
sys_str
rm(sys_str)

derepFs <- derepFastq(filtFs)
derepRs <- derepFastq(filtRs)
#sam.names <- sapply(strsplit(basename(filtFs),"_"),`[`,1)
names(derepFs) <- sample.names
names(derepRs) <- sample.names

head(out)
out
```

# Learn the error rates
```{r}
# This took 10 min
sys_str <- Sys.time()
set.seed(1) # Since we randomize what samples we use for learning the error rates, we use set.seed() to make the analysis reproducible
errF <- learnErrors(filtFs, randomize=TRUE, nbases=4e8, multithread=TRUE) # here we need to increase nbases to sample more than only 11 samples, default is 1e8
set.seed(1)
errR <- learnErrors(filtRs, randomize=TRUE, nbases=4e8, multithread=TRUE) # here we need to increase nbases to sample more than only 11 samples, default is 1e8
plotErrors(errF, nominalQ=TRUE)

# In the plots, the black line is the error model, the dots are the actual errors
sys_str[2] <- Sys.time()
sys_str
rm(sys_str)
```

# Sample inference
```{r}
sys_str <- Sys.time()
dadaFs <- dada(derepFs, err=errF, multithread=TRUE) # we could incorporate "pool=TRUE", or pool="pseudo" if pool=TRUE is too computationally demanding. 
dadaRs <- dada(derepRs, err=errR, multithread=TRUE) # we could incorporate "pool=TRUE"
sys_str[2] <- Sys.time()
sys_str
rm(sys_str)

dadaFs[[1]]
dadaRs[[1]]
```

# Merge paired reads
```{r}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE, trimOverhang=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```

# Construct sequence table
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)

# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```

# Remove sequences that appear too short or long to be real
```{r}
seqtab2 <- seqtab[,nchar(colnames(seqtab)) %in% 250:255]
```

# Remove chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab2, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
sum(seqtab.nochim)/sum(seqtab2)
```

# Track reads through the pipeline
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
tail(track)
```

# Assign taxonomy
```{r}
#assignTaxonomy using Silva 
taxa <- assignTaxonomy(seqtab.nochim, "PATH/DADA2/silva_nr99_v138_train_set.fa.gz", multithread=TRUE)
taxa <- addSpecies(taxa, "PATH/DADA2/silva_species_assignment_v138.fa.gz")

taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```

```{bash}
mkdir PATH/DADA2/analysis/03_Taxonomy
```

```{r}
pathtax <- "PATH/DADA2/analysis/03_Taxonomy/"

# Save taxonomy assignments from dada2 pipeline
write.csv2(file=paste(pathtax,"Taxtable_dada2",sep=""),taxa)
```

# Convert to fasta
```{r}
uniquesToFasta(seqtab.nochim, fout='PATH/DADA2/analysis/03_Taxonomy/seqtab.nochim.fasta', ids=colnames(seqtab.nochim))
```

# Prepare a phylogenetic tree with phangorn
```{r, eval=FALSE}
library(DECIPHER) # Make alignment with DECIPHER...
library(phangorn) # ...then build tree with phangorn
asv.seqs <- getSequences(seqtab.nochim )
names(asv.seqs) <- asv.seqs
asv.alignment <- AlignSeqs(DNAStringSet(asv.seqs), anchor=NA)

# convert to phangorn and run phylogenetic tree reconstruction
phang.align <- phyDat(as(asv.alignment, "matrix"), type="DNA")
dm <- dist.ml(phang.align)
treeNJ <- NJ(dm) # Note, tip order != sequence order
fit = pml(treeNJ, data=phang.align)

## negative edges length changed to 0!

fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
                      rearrangement = "stochastic", control = pml.control(trace = 0))
detach("package:phangorn", unload=TRUE)

```

# Evaluate accuracy
```{r}
unqs.mock <- seqtab.nochim["MOCK1",] 
unqs.mock <- sort(unqs.mock[unqs.mock>0], decreasing=TRUE) # Drop ASVs absent in the Mock
cat("DADA2 inferred", length(unqs.mock), "sample sequences present in the Mock community.\n")

mock.ref <- getSequences(file.path(path, "PATH/DADA2/mock_seq_plasmids.fasta"))
match.ref <- sum(sapply(names(unqs.mock), function(x) any(grepl(x, mock.ref))))
cat("Of those,", sum(match.ref), "were exact matches to the expected reference sequences.\n")
```

# **Load and filter the data in phyloseq**
```{r, eval=FALSE}
library(ggplot2)
library(vegan) # ecological diversity analysis
library(dplyr)
library(scales) # scale functions for vizualizations
library(grid)
library(RColorBrewer)
library(reshape2) # data manipulation package
library(cowplot)
library(phyloseq)
library(tidyverse)
library(readxl)

# setting the working directory
setwd("PATH/DADA2/")

# Set plotting theme
theme_set(theme_bw())

#Data frame containing sample information
samdf = read.csv("/Volumes/My Passport for Mac/MiSeqRun_Analyses/Microbiota_MetaData.csv", header = T, fill=TRUE) # fill=TRUE allows to read a table with missing entries
rownames(samdf) = samdf$Sample_ID

#Create a phyloseq object
ps.raw <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxa), 
               phy_tree(fitGTR$tree)) 
sample_data(ps.raw) 


dput(sample_names(ps.raw)) # Check sample names
```

# Export raw ASV table
```{r}
table = merge( tax_table(ps.raw),t(otu_table(ps.raw)), by="row.names")

#write.table(table, "PATH/DADA2/RawASVtable_SINA.txt", sep="\t")
write.table(table, "PATH/DADA2/RawASVtable_dada2taxa.txt", sep="\t")
```

# Filter the table and clean the classification
```{r}
#Filter out Eukaryota, mitochondria and chloroplast reads
ps <- subset_taxa(ps.raw, #Family  != "Mitochondria" | is.na(Family)  &
                      #Order   != "Chloroplast" | is.na(Order)  &
                      Kingdom !="Eukaryota" | is.na(Kingdom) &
                      Kingdom !="Unclassified" | is.na(Kingdom), 
                      prunesamples=TRUE)

# give new names to ASV's
dna <- Biostrings::DNAStringSet(taxa_names(ps))
names(dna) <- taxa_names(ps)
ps <- merge_phyloseq(ps, dna)
taxa_names(ps) <- paste0("ASV", seq(ntaxa(ps)))
ps

# Instead of having NAs in the taxa names, at all levels of taxonomical assignment we replace them with the lowest level that the classifier could achieve
tax <- data.frame(tax_table(ps))

tax.clean <- data.frame(row.names = row.names(tax),
Kingdom = str_replace(tax[,1], "D_0__",""),
Phylum = str_replace(tax[,2], "D_1__",""),
Class = str_replace(tax[,3], "D_2__",""),
Order = str_replace(tax[,4], "D_3__",""),
Family = str_replace(tax[,5], "D_4__",""),
Genus = str_replace(tax[,6], "D_5__",""),
Species = str_replace(tax[,7], "D_6__",""), # uncheck this if using the Silva classification from DADA2, as that one also has the species column
stringsAsFactors = FALSE)
tax.clean[is.na(tax.clean)] <- ""

for (i in 1:7){ tax.clean[,i] <- as.character(tax.clean[,i])} # Change for (i in 1:6) to for (i in 1:7) if using the classification from DADA2 as that one also has the species column
####### Fille holes in the tax table
tax.clean[is.na(tax.clean)] <- ""
for (i in 1:nrow(tax.clean)){

#Fill in missing taxonomy

if (tax.clean[i,2] == ""){
kingdom <- paste("Kingdom_", tax.clean[i,1], sep = "")
tax.clean[i, 2:6] <- kingdom    # Change all the 2:6, 3:6 and so on to 2:7, 3:7 etc if using the classification from DADA2 as that one also has the species column
} else if (tax.clean[i,3] == ""){
phylum <- paste("Phylum_", tax.clean[i,2], sep = "")
tax.clean[i, 3:6] <- phylum
} else if (tax.clean[i,4] == ""){
class <- paste("Class_", tax.clean[i,3], sep = "")
tax.clean[i, 4:6] <- class
} else if (tax.clean[i,5] == ""){
order <- paste("Order_", tax.clean[i,4], sep = "")
tax.clean[i, 5:6] <- order
} else if (tax.clean[i,6] == ""){
family <- paste("Family_", tax.clean[i,5], sep = "")
tax.clean[i, 6:6] <- family
} else if (tax.clean[i,6] == ""){
tax.clean$Species[i] <- paste("Genus",tax.clean$Genus[i], sep = "_")
}
}

tax_table(ps) <- as.matrix(tax.clean)
```

# Save the phyloseq object so next time you do not need to rerun the analysis from scratch 
```{r}
saveRDS(ps, "PATH/DADA2/ps_dada2taxa_MultiplexNetwork.rds")

# Grab the XStringSet object with the OTU/ASV sequences
rs <- refseq(ps)
rs # inspect
# Get strings with the full taxonomy for each OTU/ASV
tax <- tax_table(ps)
head(tax) # inspect
tax_strings <- apply(tax, 1, paste, collapse=";")
head(tax_strings) # inspect
# Create new names for the sequences in the refseq object; these will become
# the sequence headers in the fasta file. Here, I set these to be the OTU/ASV
# name and the tax string separated by one space (determined by the sep
# parameter)
new_names <- paste(taxa_names(ps), tax_strings, sep = " ")
head(new_names) # inspect
# Update the refeq names and save as a fasta file
names(rs) <- new_names
rs # inspect
Biostrings::writeXStringSet(rs, "PATH/DADA2/analysis/03_Taxonomy/AllRawASVs.fasta")
```

# **You can start the analysis from here if you saved the ps object**
```{r}
library(ggplot2)
library(vegan) # ecological diversity analysis
library(dplyr)
library(scales) # scale functions for vizualizations
library(grid)
library(RColorBrewer)
library(reshape2) # data manipulation package
library(cowplot)
library(phyloseq)
library(tidyverse)
library(readxl)
library(dada2)

#ps <- readRDS("PATH/DADA2/ps_SINA_Hanine.rds")
ps <- readRDS("PATH/DADA2/ps_dada2taxa_MultiplexNetwork.rds")

#Data frame containing sample information
samdf = read.csv("PATH/Microbiota_MetaData.csv", header = T, fill=TRUE, na.strings=c(""," ","NA"), row.names = 1) # fill=TRUE allows to read a table with missing entries

```

# Plot distribution of reads per sample 
```{r}
# Make a data frame with a column for the read counts of each sample
sample_sum_df <- data.frame(sum = sample_sums(ps))

# Histogram of sample read counts
dev.new()
ggplot(sample_sum_df, aes(x = sum)) + 
  geom_histogram(color = "black", fill = "indianred", binwidth = 1000) +
  ggtitle("Distribution of sample sequencing depth") + 
  xlab("Read counts") +
  theme(axis.title.y = element_blank())

# mean, max and min of sample read counts
smin <- min(sample_sums(ps))
smean <- mean(sample_sums(ps))
smax <- max(sample_sums(ps))

# printing the results
cat("The minimum sample read count is:",smin)
cat("The average sample read count is:",smean)
cat("The maximum sample read count is:",smax)

# setting the seed to one value in order to create reproducible results
set.seed(1)  
```

# Get proportions
```{r}
library(genefilter)
proportions = transform_sample_counts(ps, function(x) {x/sum(x)})
```

# Plot bacterial stacked bars
```{r}
mdf = psmelt(proportions)
mdf <- mdf[order(factor(mdf$Maturity, ordered=TRUE), mdf$SampleType, mdf$Sample), ]  
mdf$Sample <- factor(mdf$Sample, levels = unique(mdf$Sample), ordered=TRUE)  # we need to do this to retain the order in plot.
tail(mdf, 4)

library(RColorBrewer)
cbPalette<-colorRampPalette(brewer.pal(12, "Paired"))

set.seed(7) # Here we use set.seed to make the colors reproducible, becasue in the scale_fill_manual we use "sample" to shuffle the order of colors in the palette
p1 = ggplot(mdf, aes_string(x = "Sample", y = "Abundance", fill = "Genus")) +
        geom_bar(stat = "identity", position = "stack", color = "black") +
        ylab("Relative abundance") +
        theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5), legend.position="bottom") +
        scale_fill_manual(values=sample(cbPalette(65))) 
  
print(p1, width = 1000, height = 200)
```

# Plot stacked bars of the various control samples (blanks, mock, negative PCR controls)
# Plotting only ASVs that have at least 1% relative abundance in 1 sample
```{r}
ps.blanks <- subset_samples(ps, SampleType == "blank") 
ps.mock <- subset_samples(ps, SampleType == "mock")

library(genefilter)
proportions.blanks = transform_sample_counts(ps.blanks, function(x) {x/sum(x)})
Filtered.blanks = filter_taxa(proportions.blanks, filterfun(kOverA(1, 0.01)), TRUE)
proportions.mock = transform_sample_counts(ps.mock, function(x) {x/sum(x)})
Filtered.mock = filter_taxa(proportions.mock, filterfun(kOverA(1, 0.01)), TRUE)
```


```{r}
mdf.blanks = psmelt(Filtered.blanks)
mdf.mock = psmelt(Filtered.mock)

# Make a color palette
library(RColorBrewer)
cbPalette<-colorRampPalette(brewer.pal(9, "Paired"))

p2 = ggplot(mdf.blanks, aes_string(x = "Sample", y = "Abundance", fill = "Genus")) +
  geom_bar(stat = "identity", position = "stack", color = "black", size = 0.2) +
  ylab("Relative abundance in blank DNA") +
  xlab(element_blank()) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5), legend.position="bottom") +
  scale_fill_manual(values=cbPalette(12)) 

p3 = ggplot(mdf.mock, aes_string(x = "Sample", y = "Abundance", fill = "Genus")) +
  geom_bar(stat = "identity", position = "stack", color = "black", size = 0.2) +
  ylab("Relative abundance in mock DNA") +
  xlab(element_blank()) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5), legend.position="bottom") +
  scale_fill_manual(values=cbPalette(7)) 

print(p2, width = 1000, height = 200)
print(p3, width = 1000, height = 200)
```


# Save plots to pdf
```{r}
dev.new()
pdf(file="Barplots_allsample-MultiplexNetwork.pdf",width=12,height=6, pointsize=4)
p1
dev.off()

dev.new()
pdf(file="Barplots_ControlSamples-MultiplexNetwork.pdf", width=14,height=25, pointsize=4)
plot_grid(p2, p3, labels = c("A", "B"), ncol = 1, nrow = 2, rel_heights = c(1.5,1))
dev.off()
```

# Distribution of library sizes
```{r}
df <- as.data.frame(sample_data(ps)) # Put sample_data into a ggplot-friendly data.frame
df$LibrarySize <- sample_sums(ps)
df <- df[order(df$LibrarySize),]
df$Index <- seq(nrow(df))
ggplot(data=df, aes(x=Index, y=LibrarySize, color=Negative)) + geom_point() 
ggsave(file="DistributionLibrarySizes.pdf", width=8, height=6, useDingbats=FALSE)
```

```{r}
ps.nomock <- prune_samples(sample_names(ps) != "MOCK1",ps) # Remove mock
ps.nomock <- prune_samples(sample_names(ps.nomock) != "MOCK2", ps.nomock)
ps.nomock <- prune_samples(sample_names(ps.nomock) != "MOCK3", ps.nomock)
ps.nomock <- prune_samples(sample_names(ps.nomock) != "MOCK4", ps.nomock)
ps.nomock = filter_taxa(ps.nomock, function(x) sum(x) > 0, TRUE)
ps.nomock
```


# **Check which sequences are likely to be contaminants (frequency method)**
```{r}
library(decontam); packageVersion("decontam")
contamdf.freq <- isContaminant(ps.nomock, method="frequency", conc="Picogreen")
head(contamdf.freq)
table(contamdf.freq$contaminant)

which(contamdf.freq$contaminant)
```

# Plot frequencies of identified contaminants vs. their concentrations after PCR
```{r}
plot_frequency(ps.nomock, taxa_names(ps.nomock)[sample(which(contamdf.freq$contaminant), )], conc="Picogreen") + 
  xlab("DNA Concentration (PicoGreen ng/μl)")
ggsave(file="ContaminantFreqVsPicogreenConc.pdf", width=12, height=10, useDingbats=FALSE)
```

# Check which sequences are likely to be contaminants (prevalence method)
```{r}
contamdf.prev <- isContaminant(ps.nomock, neg = "Negative", normalize = TRUE, threshold = 0.1, detailed = T)
table(contamdf.prev$contaminant)

head(which(contamdf.prev$contaminant))

```

# Plot prevalences of identified contaminants
```{r}
# Make phyloseq object of presence-absence in negative controls and true samples
ps.pa <- transform_sample_counts(ps.nomock, function(abund) 1*(abund>0))
ps.pa.neg <- prune_samples(sample_data(ps.pa)$Negative == "TRUE", ps.pa)
ps.pa.pos <- prune_samples(sample_data(ps.pa)$Negative == "FALSE", ps.pa)
# Make data.frame of prevalence in positive and negative samples
df.pa <- data.frame(pa.pos=taxa_sums(ps.pa.pos), pa.neg=taxa_sums(ps.pa.neg),
                      contaminant=contamdf.prev$contaminant)
ggplot(data=df.pa, aes(x=pa.neg, y=pa.pos, color=contaminant)) + geom_point(size=3, position=position_jitter(h=0.05,w=0.05)) +
  xlab("Prevalence (Negative Controls)") + ylab("Prevalence (True Samples)")
ggsave(file="ContaminantPrevalences.pdf", width=8, height=6, useDingbats=FALSE)
```

# Both methods combined
```{r}
contamdf.both <- isContaminant(ps.nomock, conc = "Picogreen", neg = "Negative", method = "either", normalize = TRUE, detailed = T)
table(contamdf.both$contaminant)

head(which(contamdf.both$contaminant))

```

# Inspect and filter identified contaminants
```{r}
# Make a phyloseq object with only the contaminants
contaminants <- prune_taxa(contamdf.both$contaminant, ps.nomock)
tax_table(contaminants)

contam.names <- taxa_names(contaminants)
contam.names

library(genefilter)
proportions = transform_sample_counts(ps, function(x) {x/sum(x)})
contam.merged <- prune_taxa(contam.names,proportions)
cont.rel = psmelt(contam.merged)
ps.rel = psmelt(proportions)
ps.rel$AbundPico <- ps.rel$Abundance * ps.rel$Picogreen # subset by column

library(RColorBrewer)
cbPalette<-colorRampPalette(brewer.pal(12, "Paired"))
cont.rel$AbundPico <- cont.rel$Abundance * cont.rel$Picogreen # subset by column
cont.rel <- cont.rel[order(factor(cont.rel$Negative, levels = c("TRUE", "FALSE"), ordered=TRUE), cont.rel$Negative, cont.rel$Sample), ]  # Let's first sort samples
cont.rel$Sample <- factor(cont.rel$Sample, levels = unique(cont.rel$Sample), ordered=TRUE)  # we need to do this to retain the order in plot.
tail(cont.rel, 4)
cont.rel$Negative = factor(cont.rel$Negative, levels=c('TRUE','FALSE'))
levels(cont.rel$Negative) <- c(levels(cont.rel$Negative), "Control samples (blanks and H2O)")
levels(cont.rel$Negative) <- c(levels(cont.rel$Negative), "Experimental samples")                              
cont.rel$Negative[cont.rel$Negative == 'TRUE'] <- 'Control samples (blanks and H2O)'
cont.rel$Negative[cont.rel$Negative == 'FALSE'] <- 'Experimental samples'

cont1 <- ggplot(cont.rel, aes_string(x = "Sample", y = "Abundance", fill = "OTU")) +
  geom_bar(stat = "identity", position = "stack", color = "black", size = 0.2) +
  ylab("Relative abundance") +
  xlab(element_blank()) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5), legend.position="none") +
  scale_fill_manual(values=cbPalette(35)) +
  facet_grid(. ~ Negative, scale="free_x", space = "free_x") +
  ggtitle("Relative Abundance of Contaminant ASVs") 

cont2 <- ggplot(cont.rel, aes_string(x = "Sample", y = "AbundPico", fill = "OTU")) +
  geom_bar(stat = "identity", position = "stack", color = "black", size = 0.2) +
  ylab("16S copies per ngDNA") +
  xlab(element_blank()) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5), legend.position="bottom") +
  scale_fill_manual(values=cbPalette(35)) +
  facet_grid(. ~ Negative, scale="free_x", space = "free_x") +
  ggtitle("Abundance of Contaminant ASVs, Normalized by DNA")

cont3 <- ggplot(cont.rel, aes_string(x = "Sample", y = "Abundance", fill = "Genus")) +
  geom_bar(stat = "identity", position = "stack", color = "black", size = 0.2) +
  ylab("Relative abundance") +
  xlab(element_blank()) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5), legend.position="none") +
  scale_fill_manual(values=cbPalette(35)) +
  facet_grid(. ~ Negative, scale="free_x", space = "free_x") +
  ggtitle("Relative Abundance of Contaminant Genera")

cont4 <- ggplot(cont.rel, aes_string(x = "Sample", y = "AbundPico", fill = "Genus")) +
  geom_bar(stat = "identity", position = "stack", color = "black", size = 0.2) +
  ylab("16S copies per ngDNA") +
  xlab(element_blank()) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5), legend.position="bottom") +
  scale_fill_manual(values=cbPalette(35)) +
  facet_grid(. ~ Negative, scale="free_x", space = "free_x") +
  ggtitle("Abundance of Contaminant ASVs, Normalized by DNA")


library(cowplot)
plot_grid(cont1,cont2,nrow=2,align = "v", rel_heights=c(2,4.5), labels="AUTO")
ggsave(file="ContaminantASVs_noMock.pdf", width=20, height=15, useDingbats=FALSE)
plot_grid(cont3,cont4,nrow=2,align = "v", rel_heights=c(2,3.5), labels="AUTO")
ggsave(file="ContaminantGenera_noMock.pdf", width=20, height=15, useDingbats=FALSE)
# plot_grid(cont5,cont6,nrow=2,align = "v", rel_heights=c(2,2), labels="AUTO")
# ggsave(file="ContaminantASVs_Acinetobacter.pdf", width=20, height=15, useDingbats=FALSE)
# plot_grid(cont7,cont8,nrow=2,align = "v", rel_heights=c(2,2), labels="AUTO")
# ggsave(file="ContaminantASVs_Pseudomonas.pdf", width=20, height=15, useDingbats=FALSE)
```

# Make a new phyloseq object after filtering out the contaminants
```{r}
ps.noncontam <- prune_taxa(!contamdf.both$contaminant, ps.nomock)
ps.noncontam
```

# Remove non experimental samples before replotting qPCR and MiSeq results
```{r}
ps.noncontam.filt <- prune_samples(ps.noncontam@sam_data$SampleType == "Experimental", ps.noncontam)
ps.noncontam.filt = filter_taxa(ps.noncontam.filt, function(x) sum(x) > 0, TRUE)
ps.noncontam.filt
```

# Save filtered ASV table (not normalised by qPCR yet)
```{r}
write.table(otu_table(ps.noncontam.filt), "MultiplexNetwork_ASVtable_Filtered.txt", sep="\t")
```

# Retain only OTUs that have at least 1% relative abundance in minimum 1 sample
```{r}
library(genefilter)
mothur_proportions = transform_sample_counts(ps.noncontam.filt, function(x) {x/sum(x)})
Filtered = filter_taxa(mothur_proportions, filterfun(kOverA(1, 0.01)), TRUE)
```

# Plot bacterial stacked bars
```{r}
mdf = psmelt(Filtered)

mdf <- mdf[order(mdf$Colony, factor(mdf$Maturity, ordered=TRUE), mdf$Sample), ] # sort
mdf$Sample <- factor(mdf$Sample, levels = unique(mdf$Sample), ordered=TRUE)  # to retain the order in plot.

set.seed(2) # Change the number within parentheses to change the order of colors in the plot. Here we use set.seed to make the colors reproducible, because in scale_fill_manual we use "sample" to shuffle the color order.
p1 = ggplot(mdf, aes_string(x = "Sample", y = "Abundance", fill = "Genus")) +
        geom_bar(stat = "identity", position = "stack", color = "black") +
        ylab("Relative abundance") +
        facet_grid(.~Colony, scale="free_x", space = "free_x") +
        labs(y= "Relative abundance", x= "Worker ID", fill = "Symbiont") + 
        theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5), legend.position="bottom") +
        scale_fill_manual(values=sample(cbPalette(9))) 
```

## Export to pdf
```{r, eval=FALSE}
dev.new()
pdf(file="Barplots_Experimentalsamples.pdf",width=15,height=5, pointsize=4)

p1

dev.off()

p1
```

# To save the session
```{r}
save.image("PATH/DADA2/MutliplexNetwork_Ampliseq.rdata")
# Close R, Re-open R
#load("path/to/my_session.rdata")
```


# Session info
```{r}
sessionInfo()
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

